<!DOCTYPE html>
<html>
<title>SWCPHD 2017</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link href='https://fonts.googleapis.com/css?family=Hammersmith One' rel='stylesheet'>
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<style>

body, h1,h2,h3,h4,h5,h6 {font-family: "Hammersmith One"}
.w3-row-padding img {margin-bottom: 12px}
/* Set the width of the sidebar to 120px */
.w3-sidebar {width: 120px;background: #222;}
/* Add a left margin to the "page content" that matches the width of the sidebar (120px) */
#main {margin-left: 100px}
/* Remove margins from "page content" on small screens */
@media only screen and (max-width: 600px) {#main {margin-left: 0}}
</style>
<body class="w3-light-grey">
<!-- Icon Bar (Sidebar - hidden on small screens) -->
<nav class="w3-sidebar w3-bar-block w3-small w3-hide-small w3-center w3-indigo">
  <!-- Avatar image in top left corner -->
<img src="US.png"  width="120" height="120">
  <a href="index.html" class="w3-bar-item w3-grey  w3-button w3-padding-large w3-indigo w3-btn">
    <i class="fa fa-home w3-xxlarge"></i>
    <p>HOME</p>
  </a>
  <a href="people.html" class="w3-bar-item w3-grey w3-button w3-padding-large w3-hover-indigo w3-btn">
    <i class="fa fa-group w3-xxlarge"></i>
    <p>PEOPLE</p>
  </a>
  <a href="courses.html" class="w3-bar-item w3-grey w3-button w3-padding-large w3-hover-indigo w3-btn">
    <i class="fa fa-flask w3-xxlarge"></i>
    <p>COURSES</p>
  </a>
  <a href="blog.html" class="w3-bar-item w3-grey w3-button w3-padding-large w3-hover-indigo w3-btn">
    <i class="fa fa-comments w3-xxlarge"></i>
    <p>BLOG</p>
  </a>
</nav>

<!-- Navbar on small screens (Hidden on medium and large screens) -->
<div class="w3-top w3-hide-large w3-hide-medium" id="myNavbar">
 <div class="w3-bar w3-black w3-opacity w3-hover-opacity-off w3-center w3-small">
    <a href="#home" class="w3-bar-item w3-button" style="width:25% !important">HOME</a>
    <a href="#people" class="w3-bar-item w3-button" style="width:25% !important">PEOPLE</a>
    <a href="#courses" class="w3-bar-item w3-button" style="width:25% !important">COURSES</a>
    <a href="#blog" class="w3-bar-item w3-button" style="width:25% !important">BLOG</a>
  </div>
</div>


<!-- Page Content -->
  <!-- EEG/EMG Section -->
   <div class="w3-padding-64 w3-content w3-text-indigo" id="blog">
    <h2 class="w3-text-Indigo">Introduction </h2>
	 <p>The first electrophysiological recordings were performed in 1949 by Gilbert N. Ling and Ralf W. Gerard, who developed microelectrodes 
	 allowing them to perform intracellular recordings of the membrane potential of a frog's muscle. In 1960, micropipettes filled with liquid 
	 were used by Alfred Strickholm. They had the tiny tip diameter on a scale of several micrometers and were used for extracellular recordings from muscle cells. 
	 In the 50 years to follow, the setup for electrophysiological recordings did not change much, and the majority of work in the field is performed with small number of electrodes, 
	 allowing to record from small subsets of neurons in a single brain region. 
	 It was only in 2016 that a new generation of electrophysiology probes got developed by collaborative effort of scientists in the laboratories in Janelia Research Campus, UCL, Allen Institute for Brain Science and some other institutions. 
	 Those revolutionary probes are called NeuroPixel; they have ~1,000 recording sites, with an opportunity to record from 384 distinct recording channels simultaneously, across the different regions in the brain. 
	 Another probe, called NeuroSeeker, was developed as well, allowing to record from nearly 1500 channels at once.
	 This, of course, opens completely new research avenues, such as studying how microcircuits process stimulus, work on planning the upcoming action, and how different layers and even regions in the brain interact with each other.
	 We performed one of our recordings with NeuroPixel probe, and another one with NeuroSeeker probe.</p>
    <div style="text-align: center;" "margin-top">
	<img src="neuropixel.png" align="middle" width="150" height="300" >
	</div>
	<hr style="width:200px" class="w3-opacity">
    <h2 class="w3-text-Indigo">Creating an auditory stimulus </h2>
	<p>The idea behind our experiments is that we wanted to discover activity in the motor cortex, associated with auditory stimuli. In order to do so, we have developed a paradigm, where we 
	play a one-second tone of a certain frequency (20 kHz), which is within rat's hearing range, every two seconds. Then, after a random number of trials, which is around 50 times, we switch to a tone of 20Hz, which is 
	within human, but not rat's hearing range. After playing this unexpected tone a couple of times, we switch back to the expected 20 kHz stimulus and repeat the procedure. We expect to see activity in the rat's motor cortex, 
	associated with the 20 kHz sound, so that the number of spikes will be different during the tone presentation as compared to the baseline. 
	We also expect that when we play the 20Hz stimulus, the brain activity will be significantly different from either baseline or the activity during the 20 kHz tone.
	In order to be able to analyse our data, and synchronize it with the stimulus that we were presenting, we sent synchronization pulses, called TTL pulses, as we were playing the sound. 
	We utilized different pulses for two types of tones that we played.
	We tested that our paradigm works when Andre Marques-Smith, postdoctoral researcher from Kampff lab, was doing his experiment with NeuroPixel probe. 
	After making sure that our stimulus works, we proceeded to the NeuroSeeker experiment performed by George Dimitriadis, postdoc in Kampff lab. He recorded brain data for 20 minutes using our paradigm. </p>
	<div style="text-align: center;" "margin:70px;">
	<img src="eph2.jpg" width="400" height="300" >
	<img src="eph3.jpg" width="400" height="300">
	</div>
    <hr style="width:200px" class="w3-opacity">
    <h2 class="w3-text-Indigo">Building our own motor </h2>
	<p> When inserting the electrical probe into the brain, manually operating axes of the manipulator can be laborious and the speed of descending the probe can vary a lot. 
	Therefore, we decided to improve our manipulator that can lower the electrical probe automatically. As our first product, we equipped a manipulator with a motor for Z-axis. 
	The equipment was 3D-printed and made of plastic, with several components including a holder to clamp our shaft, a carrier for the motor and two gears to transmit the motion. 
	Our designer Federico said “the most difficult part to DIY our manipulator set is to have a design that can hold the motor and clamp the shaft nicely and stably. 
	While rotating the gears, the gears wiggle from times to times. What we want to improve from here is to make this manipulator set more stable.” </p>
	<div style="text-align: center;" "margin-top">
	<img src="eph1.jpg" align="middle" width="400" height="300" >
	<img src="motor.jpg" align="middle" width="150" height="300" >
	</div>
	<hr style="width:200px" class="w3-opacity">
    <h2 class="w3-text-Indigo">Making a code for the motor </h2>
	<p> When moving the stereotaxis, this manipulator is connected to a computer where Bonsai, a event-driven, asynchronous environment, reads the value of how much stereotaxis moves. 
	With this, we can quantify and digitalize the position of the electrical probe. Furthermore, we used Arduino to trigger the motor for the manipulator. 
	We planned to program a feedback loop which generates commands to the motor and sends the information about the position of the electrical probe back to the computer to update the position. 
	Bonsai then compares the value from the stereotaxis with the expected value (based on remaining distance and time to run). Having this update every time can correct the errors the motor makes 
	and make our automated stereotaxis system precise. Our engineer Francesca said “This is not a trivial task. Bonsai is an event-based environment, therefore; we needed to program a loop that is compatible 
	with each event Bonsai receives and initiate the next command by Arduino.”</p>
    <hr style="width:200px" class="w3-opacity">
	<h2 class="w3-text-Indigo">Data analysis </h2>
	<p> First, we extracted data by using a Bonsai program made by Kampff lab. Then, each of us analyzed the data by creating an analysis script from scratch in Python. We extracted the spikes from all the channels, and 
	produced a heatmap of activity, relative to the stimulus onset. </p>
    <hr style="width:200px" class="w3-opacity">
    <h2 class="w3-text-Indigo"> Results </h2>
	<div style="text-align: center;" "margin:70px;">
	<img src="result_anna.png" width="800" height="200" >
	</div>
	<div style="text-align: center;" "margin:70px;">
	<img src="result_simon.png" width="200" height="800" >
	</div>
	<div style="text-align: center;" "margin:70px;">
	<img src="result_eggy.jpg" width="400" height="300" >
	<img src="result_fede.png" width="400" height="300">
	</div>
	<div style="text-align: center;" "margin:70px;">
	<img src="result_fran.png" width="400" height="300" >
	<img src="result_phil.png" width="400" height="300">
	</div>
	
</div>
    <hr style="width:200px" class="w3-opacity">
	

   
  <!-- End blog Section -->
  </div>
  
  <!-- END PAGE CONTENT -->
